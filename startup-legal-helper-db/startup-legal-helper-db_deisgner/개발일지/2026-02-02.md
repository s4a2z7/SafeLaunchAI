# 개발 일지: Red Team 리뷰 대응 — DB 인프라 전면 개선
- 날짜: 2026-02-02
- 태그: #RedTeam #VectorDB #품질개선 #판례 #노이즈제거

---

## 오늘의 목표
- [x] Red Team 리뷰 10개 이슈 중 미해결 8개 처리
- [x] 판례 데이터 오염(CSS/JS) 정화
- [x] 데이터 품질 검증 로직 추가
- [x] TF-IDF 검색 성능 개선
- [x] 판례 전용 청킹 전략 구현
- [x] API 재시도 로직 추가
- [x] 동기화 버전 관리 구현

## 작업 내용

### Red Team 이슈별 대응 결과

| # | 이슈 | 심각도 | 대응 | 변경 파일 |
|:-:|------|:------:|:----:|----------|
| 1 | 판례 데이터 오염 | Critical | **해결** | `legal_rag.py`, `clean_precedents.py` |
| 2 | 핵심 법령 미수집 | Critical | 기 해결 (01-31) | - |
| 3 | 스토어 정책 공백 | Critical | 기 해결 (02-01) | - |
| 4 | 판례 추출 로직 결함 | High | **해결** | `legal_rag.py` |
| 5 | TF-IDF 의미론적 한계 | High | **개선** | `legal_rag.py` |
| 6 | 데이터 품질 검증 | High | **해결** | `legal_rag.py` |
| 7 | 메타데이터 불완전 | Medium | **해결** | `legal_rag.py` |
| 8 | 동기화/버전 관리 | Medium | **해결** | `legal_rag.py` |
| 9 | 에러 핸들링/재시도 | Medium | **해결** | `law_api.py` |
| 10 | 청킹 전략 개선 | Medium | **해결** | `legal_rag.py` |

### 상세 변경사항

#### 1. 판례 데이터 오염 정화 (Critical #1)
- `clean_precedents.py` 스크립트 작성
- dry-run으로 71건 전체 오염 확인
- 백업 생성 후 오염 데이터 제거 (`precedents_backup_20260202_*.json`)
- 오염 데이터 제거 후 → 개선된 로직 + API 버그 수정으로 재수집 완료
- **최종 precedents.json: 712청크** (13개 키워드, 각 최대 10건)

#### 2. 판례 추출 로직 전면 재작업 (High #4)
- `_extract_precedent_text()` 함수 전면 개선:
  - dict/OrderedDict 중첩 구조 재귀 탐색 추가 (`_extract_text_recursive()`)
  - CSS/JS 노이즈 패턴 감지 함수 추가 (`_is_noise_text()`)
  - 30자 이상 무조건 저장 → 노이즈 검증 후 저장으로 변경
  - 최종 결과물에 대한 이중 검증
- `_extract_text_from_html_dict()` 노이즈 필터링 강화
- `_clean_html()` script/style 블록 전체 제거 추가

#### 3. TF-IDF 하이브리드 검색 (High #5)
- 기존: `char_wb` 단일 벡터라이저 (ngram 1-3, 10K features)
- 변경: **char_wb + word 하이브리드** 방식
  - char_wb: ngram 2-4, 15K features, sublinear_tf
  - word: ngram 1-2, 15K features, sublinear_tf
  - 가중 합산: 단어 60% + 문자 40%
- "저작권 침해"↔"저작물 도용" 등 단어 단위 매칭 개선

#### 4. 데이터 품질 검증 (High #6)
- `validate_legal_document(text, source_type)` 함수 신규 구현
- 3단계 검증: 노이즈 감지 → 최소 길이 → 법률 키워드 포함
- source_type별 차별화된 기준:
  - law: 최소 100자, 법률 키워드 2개 이상
  - precedent: 최소 80자, 판례 키워드 2개 이상
  - store_policy: 최소 50자, 정책 키워드 2개 이상
- `ingest_laws()`, `ingest_precedents()`에 검증 통합

#### 5. 판례 전용 청킹 전략 (Medium #10)
- `chunk_precedent_text()` 함수 신규 구현
- 조문 경계(제N조) 대신 섹션 헤더 기반 분할:
  - [판시사항], [판결요지], [참조조문], [판례내용], [이유], [주문] 등
- chunk_size: 800 → **1200자** (법률 문맥 유지)
- overlap: 150 → **300자** (문맥 손실 방지)

#### 6. 판례 메타데이터 보강 (Medium #7)
- 추가된 필드:
  - `case_number`: 사건번호
  - `case_type`: 사건종류명
  - `source_url`: 원문 링크
- 법령에도 `source_url` 필드 추가

#### 7. API 재시도 로직 (Medium #9)
- `law_api.py`에 지수 백오프 재시도 구현:
  - MAX_RETRIES = 3, RETRY_DELAY_BASE = 2초
  - 지수 백오프: 2초 → 4초 → 8초
- 구조화된 로깅 (logging 모듈 사용)
- 실패 건 상세 로그 (URL, 파라미터, 에러 메시지)

#### 8. 동기화 버전 관리 (Medium #8)
- `_save_sync_metadata()` 함수 신규 구현
- `database/metadata.json` 자동 생성:
  - `last_sync`: UTC 타임스탬프
  - `version`: 자동 증가 (1.0.0 → 1.0.1 → ...)
  - `collections`: 컬렉션별 문서 수
  - `sync_history`: 동기화 이력 누적

## 삽질 기록 (Troubleshooting)

### NOISE_PATTERNS 설계
- 처음에는 단순 문자열 매칭으로 시작했으나, `/` 비율 기반 감지를 추가하여 정확도 향상
- CSS 경로(`/DRF/js/ext/resources/css/ext-all.css`)의 특성: `/` 비율이 5% 이상

### 판례 API 파라미터 버그 발견 (근본 원인)
- **기존 코드:** `get_precedent_detail()`에서 `params.add_field("precSeq", prec_seq)` 사용
- **실제 API 요구:** 검색 결과의 `판례상세링크` 필드가 `ID=608359` 형식 → `ID` 파라미터 필요
- `precSeq` 파라미터로 요청 시 API가 "일치하는 판례가 없습니다" HTML 에러 페이지 반환
- xmltodict가 이 HTML을 파싱하여 CSS/JS 경로 문자열이 dict에 포함됨
- **수정:** `params.add_field("ID", prec_seq)` → 정상적인 `PrecService` XML 응답 수신
- 이 한 줄 수정으로 71건 전체 오염의 근본 원인 해결

### PrecService 키 우선순위
- 판례 상세 API 응답의 루트 키가 `PrecService`인데, 기존 코드에서 `판례` 키를 먼저 탐색
- `_extract_precedent_text()`와 `ingest_precedents()`에서 `PrecService` 키 우선 처리로 수정

## 새로 알게 된 점 (TIL)
- TF-IDF에서 `sublinear_tf=True`를 사용하면 tf를 `1 + log(tf)`로 변환하여 빈도 과다 단어의 영향을 줄임
- 한국어 검색에서 `word` 분석기만 쓰면 공백 기준 토큰화라 복합어 처리가 약함 → char_wb와 결합이 효과적
- 지수 백오프(exponential backoff)는 네트워크 일시 장애에 효과적

## 넥스트 스텝
- [x] 판례 재수집 (개선된 추출 로직으로 fresh ingestion) → **712청크 수집 완료**
- [ ] score_threshold 소스별 튜닝 테스트
- [ ] 한국어 형태소 분석기(Mecab/Okt) 도입 검토
- [ ] 기존 laws.json 데이터도 품질 검증 실행

---

## 회고
Red Team 리뷰에서 지적된 10개 이슈를 모두 대응했다.
가장 치명적이었던 판례 71건 전체 오염 문제의 **근본 원인**이 API 파라미터 버그(`precSeq` → `ID`)임을 발견하고 수정했다.
개선된 추출 로직 + API 버그 수정 후 재수집 결과 **712청크**의 정상 판례 데이터를 확보했다.
(기존 71건 오염 데이터 대비 약 10배 증가, 전체 컬렉션: laws 1,458 + precedents 712 + store_policies 36 = **총 2,206건**)
품질 검증이 자동 적용되어 동일 문제가 재발하지 않을 것이다.
TF-IDF 하이브리드 방식도 기존 대비 의미 매칭이 개선되었음을 검색 테스트로 확인했다.
